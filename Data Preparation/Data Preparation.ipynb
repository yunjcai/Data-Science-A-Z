{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools for Data Science\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/tds1.JPG?raw=true' width='500'>\n",
    "\n",
    "* **ETL(Extract Transform Load):** Use Microsoft Visual Studio (shell), which is only the business intelligence tools in Visual Studio.\n",
    "    * SSDT-BI(SQL Server Data Tools - Business Intelligence): Building SSIS/SSAS/SSRS solutions\n",
    "        * SSIS(SQL Server Integration Service): <font color='purple'>Use Microsoft Visual Studio Shell to Run SSDT-BI, then need SSIS part for ETL</font>\n",
    "        * SSAS(SQL Server Analysis Service): Analyze. But we use Python or R\n",
    "        * SSRS(SQL Server Reporting Service): Visualize. But we use Tableau\n",
    "* **Database:** <font color='dark orange'>Microsoft SQL Server</font>\n",
    "* **Analyze:** <font color='blue'>Python / R</font>\n",
    "* **Visualize:** <font color='green'>Tableau</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested Data Science Project Folder Structure\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/tds2.JPG?raw=true' width='500'>\n",
    "\n",
    "* **MMDDYYYY Project Name:** Use \"Date\" + \"Project Name\" for the Data Science Project\n",
    "    * **Original Data:** Store all the raw data extracted from other systems, and no modification.\n",
    "    * **Prepared Data:** Any modification we made to the raw data (cleaning the data).\n",
    "    * **Uploaded Data:** Temporary Stop. Need subfolder with just date(MMDDYYYY). Once the data is ready to upload, then put in these subfolders. \n",
    "    * **Analysis:** Any codes, scripts been created during the anaylsis.\n",
    "    * **Insights:** Any preliminary(初步准备) results.\n",
    "    * **Final:** Store the draft and final reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL (Phase 1: in EXCEL)\n",
    "<font color='red'>Do NOT open and save data by EXCEL directly.</font> It will mess up the original data format (ie. Date and long int).\n",
    "##### Deal with Large CSV\n",
    "**STEP 1:** Rename the extension to be <font color='blue'>\".txt\"</font><br>\n",
    "**STEP 2:** In the same directory, Go to \"Tools\" $\\rightarrow$ \"Folder options...\" $\\rightarrow$ \"View\" Tab $\\rightarrow$ Uncheck box 'Hide extensions for known file type'\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwb1.JPG?raw=true' width='300'><br>\n",
    "**STEP 3:** Use normal \"File\" $\\rightarrow$ \"Open\" to open \".txt\" data in EXCEL. Use \"Text Import Wizard\" to force EXCEL open the file correctly.<br>\n",
    "**STEP 4.1:** Make sure 'Delimited' has been selected\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwb2.JPG?raw=true' width='400'><br>\n",
    "**STEP 4.2:** Change 'Delimiter': 'Comma'(only) and 'Text qualifier': ' \" ', Check all the imported columns are correct.\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl3.JPG?raw=true' width='400'><br>\n",
    "**STEP 4.3:** Select from the 1st column to the last column. Then check 'Text' in the 'Column data format' section.\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl4.JPG?raw=true' width='400'><br>\n",
    "**STEP 5:** In general, check and fix up the \"Date\" in the data (convert txt to date)\n",
    "* Select whole \"Date\" column, then select \"Data\" $\\rightarrow$ \"Text to Columns\"\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl5.JPG?raw=true' width='400'><br>\n",
    "* Check 'Delimited', Uncheck any 'Delimiters' since only dealing with 1 column, Select 'Date' in 'Column data format' section to be \"MDY\" (Month, Day, Year)<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl6.JPG?raw=true' width='400'>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl7.JPG?raw=true' width='400'>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl8.JPG?raw=true' width='400'><br>\n",
    "* Now we can change Date type by using EXCEL \"Format Cells...\" (we will use yyyy-mm-dd in the example)<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl9.JPG?raw=true' width='400'><br>\n",
    "* Repeat the above steps for every column has \"Date\".<br>\n",
    "\n",
    "**STEP 6:** Same as STEP 5 to fix up the \"Dollar Amounts\" (convert txt to number)\n",
    "* Select whole \"Dollar\" column, then select \"Data\" $\\rightarrow$ \"Text to Columns\"\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl5.JPG?raw=true' width='400'><br>\n",
    "* Check 'Delimited', Uncheck any 'Delimiters' since only dealing with 1 column, Select 'General' in 'Column data format' section<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl6.JPG?raw=true' width='400'>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl7.JPG?raw=true' width='400'>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl10.JPG?raw=true' width='400'><br>\n",
    "* Now we can change Date type by using EXCEL \"Format Cells...\". Choose 'Number', 'Decimal places', no 'Use 1000 Separtor()', 'Negative numbers'<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl11.JPG?raw=true' width='400'><br>\n",
    "* Repeat the above steps for every column has \"Dollar\".<br>\n",
    "\n",
    "**STEP 7:** Fix the column which contain more than 256 characters\n",
    "* Select whole column, right click \"Format Cells...\" $\\rightarrow$ Select 'General' in \"Category\" section\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl12.JPG?raw=true' width='400'><br>\n",
    "\n",
    "**STEP 8:** Now save data as \".csv\" format\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/dwbl13.JPG?raw=true' width='400'><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL (Phase 2: in SSIS)\n",
    "How to upload a raw file where everything is in text into SQL<br>\n",
    "\n",
    "**STEP 1:** Open Microsoft Visual Studio $\\rightarrow$ \"New Project\" $\\rightarrow$ \"Business Intelligence\" $\\rightarrow$ \"Integration Services Project\" $\\rightarrow$ Enter \"Name\" and \"Solution Name\"<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS1.JPG?raw=true' width='400'><br>\n",
    "**STEP 2:** In the \"Control Flow\" section, drag 'Data Flow Task' from \"SSIS Toolbox\"/\"Favorites\". Then give it a name<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS2.JPG?raw=true' width='400'><br>\n",
    "**STEP 3:** Double click dragged \"Data Flow Task\" block to open \"Data Flow\" section. Drag \"Flat File Source\" from \"Other Sources\" and \"OLE DB Destination\" from \"Other Destinations\". Then connect those blocks.<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS3.JPG?raw=true' width='400'><br>\n",
    "**STEP 4.1:** Double click \"Flat File Source\" to set up.\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS4.JPG?raw=true' width='400'><br>\n",
    "**STEP 4.2:** Use \"Browse...\" to select the data, and rename the 'Connection manager name:'<br>\n",
    "**STEP 4.3:** <font color='red'>**Go to the \"Columns\" section on the left side to check the table information (ALL the time). To find which column do errors start</font>**\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS5.JPG?raw=true' width='400'><br>\n",
    "**STEP 4.4:** Select \"Advanced\" $\\rightarrow$ Select all the columns $\\rightarrow$ 设置 'OutputColumnWidth' 为1000或2000 (For long comment cell)\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS9.JPG?raw=true' width='400'><br>\n",
    "**STEP 4.5:** <font color='blue'>**用 Automating Error Handling in SSIS 来分流合格/不合格数据 (见 \"Automating Error Handling in SSIS\" 章节)**</font><br>\n",
    "**STEP 5:** <font color='red'>**Open both prepared .csv and original .csv file on the same view site in Notepad++. Compare both files to find where does error start and what causes it incorrect.</font>**(注：EXCEL会自动添加双引号\"来弥补缺少的引号\"，会造成问题)\n",
    "* Right click one of the data file $\\rightarrow$ \"Move to Other View\" (To rotate the views to be either side-by-side or top-and-bottom simply right-click the divider line)\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS7.JPG?raw=true' width='200'><br>\n",
    "* Synchronize the scrolling: \"View\" $\\rightarrow$ \"Synchronize Vertical Scrolling\"\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS8.JPG?raw=true' width='200'><br>\n",
    "\n",
    "**STEP 6:** 见\"常见问题\"章节。如果 Data 结构应 EXCEL 自动排版导致问题的话，Modify/fix the prepared data in Notepad++。如果是信息缺失，则将信息缺失行消息反馈给相应部门，让他们处理。<br>\n",
    "**STEP 7:** Double Click \"OLE DB Destination\" to CREATE TABLE in SQL server. Select the Database, then create new table with columns<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS13.JPG?raw=true' width='400'><br>\n",
    "**STEP 8:** Rename the table name, and add one column (RowNumber) with identity(1,1) manually (index and improve data search speed)\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS14.JPG?raw=true' width='400'><br>\n",
    "**STEP 7:** 点击 \"Start\" 开始将 Data 导入 SQL Server.\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS10.JPG?raw=true' width='400'><br>\n",
    "**STEP 8:** 出现 error 的话，点击底部 link，再点击新页面上的 \"Excution Results\"。\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS11.JPG?raw=true' width='400'><br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS12.JPG?raw=true' width='400'><br>\n",
    "**STEP 9:** 任何上传 Data 失败后，需要删除上传失败的 Database。回到 STEP 7 重新上传。\n",
    "##### SQL 语句：\n",
    "<font color='blue'>DROP TABLE</font> TableName <font color='green'># Delete Entire table</font><br>\n",
    "或者<br>\n",
    "<font color='blue'>TRUNCATE TABLE</font> TableName <font color='green'># Delete the data in the table, but keep the header</font><br>\n",
    "\n",
    "**STEP 10:** **完成该 block 的 Control Flow 后，必须将这个 block 给 Disable 掉。不然下次执行时，这个模块的数据会再次上传。** 执行 Control Flow 时，Control Flow 中所有模块都会同时上传数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常见问题\n",
    "如果 Data 结构应 EXCEL 自动排版导致问题的话，Modify/fix the prepared data in Notepad++。\n",
    "#### Text Qualifier\n",
    "\"Text Qualifier\": 让 SSIS 将 \"Text Qualifier\" 设定的符号(如 \")中，囊括的任何内容，视作一个整体(1个 cell)。 \"Text Qualifier\" 允许我们用设定的符号来分割内容。<br>\n",
    "\n",
    "比如, \"I am ok, how are you\". 如果 \"Text Qualifier\" 设置为空的话。将会产生两个 cell: \"I am ok\" 和 \"how are you\"。如果设置了 \"Text Qualifier\": \" 。则整个 \"I am ok, how are you\" 会在同一个 cell 里。<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/UDS6.JPG?raw=true' width='400'><br>\n",
    "#### Data 信息缺失\n",
    "如果 Data 信息缺失，某些 Columns 没有数据，判断是否重要，并且反馈给相关部门。<br>\n",
    "\n",
    "#### Data Truncation\n",
    "回到 \"Flat File Source\"，重复 STEP 4.4。增加相应 Truncation 行的 Output Column Width (如增加到5000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automating Error Handling in SSIS: Conditional Split\n",
    "<font color='blue'>通过使用 SSIS 中，\"Conditional Split\" block，设置对应过滤函数，来自动分流好/坏数据，并导入相应的 .txt 文件。</font>\n",
    "\n",
    "**STEP 1:** Delete/Truncate the created data (table) by using SQL commands in SQL Server<br>\n",
    "**STEP 2:** In SSIS, delete the connection line between \"Flat File Source\" and \"OLE DB Destination\"<br>\n",
    "**STEP 3:** In the \"SSIS Toolbox / Common / Conditional Split\". Use \"Conditional Split\" for transform. Then connect \"Flat File Source\" and \"Conditional Split\" blocks<br>\n",
    "**STEP 4:** Set up \"Conditional Split\" block. (1) Give \"Output Name\"; (2) Drag Functions from \"String Functions\" to \"Condition\"; (3) Use \"Columns\" to complete dragged function in the \"Condition\"; (4) Give the Default output name.<br>\n",
    "\n",
    "**注：通过在 Condition 里设置含有 Columns 变量的 Function，来区分 Data 是否合格。将不合格的数据分流至 \"Output Name\", 合格数据分流至 \"Default output name\"。**<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/aehs1.JPG?raw=true' width='400'/>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/aehs2.JPG?raw=true' width='400'/><br>\n",
    "\n",
    "**STEP 5:** Set up \"Flat File Destination\" to store 不合格数据。(1) 当与 \"Conditional Split\" block 连线时，\"Input Output Selection\" window 自动弹出，选择对应的 Output。(2) 随后双击，在 \"Flat File Connection Manager\" 选择 \"New...\",选择 \"Delimiter\", 在弹出的新窗口，点击 \"Browse...\"。(3) 建议在 \"Analysis\" Folder 里新建文件夹和 .txt 文件 \"Automatically Excluded Results/YYYYMMDD_ProjectName_xxxRecords.txt\" 来储存分流后的数据。并选择该新建的 .txt 文件。(4) 设置 \"Text qualifier\" 为 \"。(5) Check the box \"Column names in the first data row\"<br>。\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/aehs3.JPG?raw=true' width='400'/>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/aehs4.JPG?raw=true' width='400'/>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/aehs5.JPG?raw=true' width='400'/>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/aehs6.JPG?raw=true' width='400'/>\n",
    "<br>\n",
    "\n",
    "**STEP 6:** 回到 Use SSIS to Upload Data 章节的 STEP 5，用 Notepad++ 来查看，对比新生成的 YYYYMMDD_ProjectName_xxxRecords.txt<br>\n",
    "**STEP 7:** 可以设置多个 Conditional Split，通过多个过滤函数来分流不同的数据。<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/aehs7.JPG?raw=true' width='500'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Anomalies in SQL\n",
    "Open SQL Server and find the uploaded table in the correct DataBase. To add a filter to check where are the anomalies.<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/FAS1.JPG?raw=true' width='600'><br>\n",
    "\n",
    "Only 2 types of rows will be output: (1) not empty in Column 46 (2) no period in the Longitude column.<br>\n",
    "Since the source corruption always shifts the row to right or left. So this way helps to check the issue.\n",
    "##### SQL 语句：\n",
    "<font color='blue'>SELECT</font> *<br>\n",
    "<font color='blue'>FROM</font> TableName<br>\n",
    "<font color='blue'>WHERE</font> [last_column] <font color='blue'>NOT LIKE</font> ''<br>\n",
    "<font color='blue'>OR</font> [the_one_before_last_column] <font color='blue'>NOT LIKE</font> '%.%'<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Programming for Data Science\n",
    "\n",
    "### SELECT * \n",
    "选择 DataBase: 这样就不用每次在 table name 前，加上 DataBase path 前缀了。<br>\n",
    "**_USE DataBase_name<br>\n",
    "GO_**\n",
    "\n",
    "从 table 中选择所有 columns:<br>\n",
    "**_SELECT *<br>\n",
    "FROM [table_name]_**\n",
    "\n",
    "### Using WHERE clause to filter data\n",
    "**_SELECT [col_1], [col_2]...<br>\n",
    "FROM [table_name]<br>\n",
    "WHERE condition1 AND condition2 OR ..._**\n",
    "\n",
    "注意：因为上传的 table 里面的值全是 'text'。所以要比较数字的话，需先 **_CONVERT(FLOAT, [col_x])_**<br>\n",
    "如：CONVERT(FLOAT,[Sales]) > 100<br>\n",
    "\n",
    "### Use Regular Expressions in SQL\n",
    "只能在 **_WHERE_** 子句中使用 **_LIKE_**<br>\n",
    "**_%_** : 顶替任意数量的字符。<br>\n",
    "**_** : 只顶替 1 个字符。<br>\n",
    "\n",
    "如：选择所有 'IT' 开头的 'Order_ID'<br>\n",
    "**_SELECT *<br>\n",
    "FROM ListOfOrders<br>\n",
    "WHERE [Order_ID] LIKE 'IT%'_**<br>\n",
    "\n",
    "如：All customers whose 2nd letter in their name is 'e'\n",
    "**_SELECT *<br>\n",
    "FROM ListOfOrders<br>\n",
    "WHERE [Customer_Name] LIKE '_e%'_**<br>\n",
    "\n",
    "### Comments in SQL\n",
    "/* comments */ 或者 --\n",
    "\n",
    "### ORDER BY\n",
    "通常不会在 SQL 中使用排序。因为没有必要在数据库中展示顺序，通常在应用中排序。<br>\n",
    "按照[col_name]来排序：DESC 降序，升序是默认的<br>\n",
    "**_SELECT *<br>\n",
    "FROM [TableName]<br>\n",
    "ORDER BY [col_name] DESC_**<br>\n",
    "注意：因为上传的 Table 是 text，所以按数字列来排序，将会出现问题。需要先 convert text table into a working table 后再排序。或者 CONVERT(FLOAT,[col_name]) 或者 CAST([col_name] as FLOAT)。\n",
    "\n",
    "### Data Types in SQL\n",
    "VARCHAR(n): n 字节的可变长度<br>\n",
    "INT: $-2^31$ ~ $2^31-1$整数<br>\n",
    "FLOAT: 浮点数，1040.53<br>\n",
    "DATE: 日期，2015-08-11<br>\n",
    "\n",
    "### Implicit Data Conversion in SQL\n",
    "因为导入SQL的表格数据是 text 类型 (varchar)，所以下表为 varchar 能隐式转换的类型(灰色为可以，黑色不可以)<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql1.JPG?raw=true' width='600'>\n",
    "\n",
    "### Using CAST() vs CONVERT() 显式转换\n",
    "**_CONVERT(FLOAT,[col_name]) 或者 CAST([col_name] as FLOAT)_**<br>\n",
    "转换日期 Dates，只能用 **_CONVERT()_**\n",
    "\n",
    "### Working with NULLs\n",
    "In SQL Server, alter the table value to be NULL: 当 Col_x 等于某值 y 时，替换 y 为 NULL<br>\n",
    "**_UPDATE [Table_Name]<br>\n",
    "SET [Col_x] = NULL<br>\n",
    "WHERE [Col_x] = value_**<br>\n",
    "\n",
    "找出哪些 value 是(不是) NULL:<br>\n",
    "**_SELECT [col_1],[col_2],[col_3]...<br>\n",
    "FROM [TableName]<br>\n",
    "WHERE [col_x] IS (NOT) NULL_**<br>\n",
    "\n",
    "### Types of JOINs\n",
    "##### INNER JOIN\n",
    "通过表格中指定 column 的相同元素，剔除不同，进行合并。<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql2.JPG?raw=true' width='400'>\n",
    "##### LEFT (OUTER) JOIN\n",
    "左侧的表格为主表，左侧表中指定的合并 column 为主列，合并后，左侧表内容都在，右侧表指定 column 中与左表不同的行，全部删除。合并后，左表缺失数据为 NULL。<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql3.JPG?raw=true' width='400'>\n",
    "##### RIGHT (OUTER) JOIN\n",
    "和 LEFT JOIN 相似。右表为主表，保留右表指定列的内容，合并后，删除左表不同行。<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql4.JPG?raw=true' width='400'>\n",
    "##### FULL (OUTER) JOIN\n",
    "合并表格内容全部保留，指定列中相同元素对应合并。其他不同处，缺失元素为 NULL。<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql5.JPG?raw=true' width='400'>\n",
    "\n",
    "最常用的是 INNER JOIN 和 LEFT JOIN。\n",
    "\n",
    "### Duplicates in JOINs\n",
    "##### INNER JOIN\n",
    "比对指定 column 中的相同元素，如果表中相同指定列的行数不相等，则复制行直至与对应表中行数相同。<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql6.JPG?raw=true' width='400'>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql7.JPG?raw=true' width='400'>\n",
    "\n",
    "### JOIN on Multiple Fields\n",
    "合并 Key 由多列组成。如下表中由 \"Store\" 和 \"Order #\" 组成合并 Key。单由 \"Order #\" 作为合并 Key，将有歧义。<br>\n",
    "下例中，想找出某一单和某个客户总共的消费<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql8.JPG?raw=true' width='400'>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql9.JPG?raw=true' width='400'>\n",
    "\n",
    "### Practicing JOINs\n",
    "**_SELECT *<br>\n",
    "FROM [TableA] as A<br>\n",
    "LEFT JOIN [TableB] as B<br>\n",
    "ON A.[Col_x] = B.[Col_y]_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL (Phase 3: in SQL) \n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql10.JPG?raw=true' width='400'><br>\n",
    "* RAW Table: Formatted as Text. We need format it properly (numbers with decimal to be float, dates to be dates...)\n",
    "* Working Table: We will use \"Stored Procedure\"(script) in SQL to build Working Table from RAW Table. Normally, ETL is end once we got the Working Table, we can connect it to different analytical tools (Tableau, Python...)\n",
    "* Derived Table: Use SQL to combine all Working Tables into the Derived Table, and then analysis it.\n",
    "\n",
    "### Stored Procedures\n",
    "Type the code between BEGIN to END and it's the only way to save the SQL code.<br>\n",
    "不推荐用 save 键，运行整个 Proc (只运行 PROC body BEGIN...END 不会 save)，就会自动 save。<br>\n",
    "Only can \"CREAT\" PROC once at first time, then it will show \"ALTER\" to modify next open.<br>\n",
    "\n",
    "**STEP 1:** 按下图修改基本格式和信息<br>\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql11.JPG?raw=true' width='500'><br>\n",
    "**STEP 2:** 基于原 RAW Table, 生成(CREATE) Working Table。在 CREATE TABLE 时，设置 Column 的 Data Type。\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql13.JPG?raw=true' width='500'><br>\n",
    "**STEP 3:** 用 **_INSERT INTO...SELECT_** 从 RAW Table 中复制插入新的 Working Table。SQL会通过隐式转换，自动转换数据类型。\n",
    "<img src='https://github.com/yunjcai/Data-Science-A-Z/blob/master/Data%20Preparation/sql15.JPG?raw=true' width='700'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
